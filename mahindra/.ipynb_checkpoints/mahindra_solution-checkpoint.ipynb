{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "## Food & Beverages Spend Prediction in Club Mahindra Resorts\n",
    "Club Mahindra (Club M) makes significant revenue from Food and Beverages (F&B) sales in their resorts. The members of Club M are offered a wide variety of items in either buffet or Ã€ la carte form. Following are some benefits that the model to predict the spend by a member in their next visit to a resort will bring:\n",
    "1. Predicting the F&B spend of a member in a resort would help in improving the pre-sales during resort booking through web and mobile app\n",
    "2. Targeted campaigns to suit the member taste and preference of F&B\n",
    "3. Providing members in the resort with a customized experience and offers\n",
    "4. Help resort kitchen to plan the inventory and food quantity to be prepared in advance\n",
    "\n",
    "Given the information related to resort, club member, reservation etc. the task is to predict average spend per room night on food and beverages for the each reservation in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission_dlc0jkw', 'test_jwt0mqh', 'train_5clrc8b']\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas_profiling\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "import fastai\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the date parser\n",
    "date_parser = lambda x: pd.datetime.strptime(x, \"%d/%m/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 756 ms, total: 23.1 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\n",
    "    \"../input/train_5clrc8b/train.csv\",\n",
    "    parse_dates=[\"booking_date\", \"checkin_date\", \"checkout_date\"],\n",
    "    date_parser=date_parser,\n",
    ")\n",
    "test = pd.read_csv(\n",
    "    \"../input/test_jwt0mqh/test.csv\",\n",
    "    parse_dates=[\"booking_date\", \"checkin_date\", \"checkout_date\"],\n",
    "    date_parser=date_parser,\n",
    ")\n",
    "sample_submission = pd.read_csv(\n",
    "    \"../input/sample_submission_dlc0jkw/sample_submission.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_id</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>checkout_date</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>main_product_code</th>\n",
       "      <th>numberofadults</th>\n",
       "      <th>numberofchildren</th>\n",
       "      <th>persontravellingid</th>\n",
       "      <th>resort_region_code</th>\n",
       "      <th>resort_type_code</th>\n",
       "      <th>room_type_booked_code</th>\n",
       "      <th>roomnights</th>\n",
       "      <th>season_holidayed_code</th>\n",
       "      <th>state_code_residence</th>\n",
       "      <th>state_code_resort</th>\n",
       "      <th>total_pax</th>\n",
       "      <th>member_age_buckets</th>\n",
       "      <th>booking_type_code</th>\n",
       "      <th>memberid</th>\n",
       "      <th>cluster_code</th>\n",
       "      <th>reservationstatusid_code</th>\n",
       "      <th>resort_id</th>\n",
       "      <th>amount_spent_per_room_night_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07659f3758d8aee27f5a7e2887adeacb67021cb95ada1b...</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...</td>\n",
       "      <td>7.706428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03930f033646d073462b35d411616323597715ac4fc398...</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>39fa9ec190eee7b6f4dff1100d6343e10918d044c75eac...</td>\n",
       "      <td>6.662563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d145a32920e6587ad95bfe299d80c0affa268220535aaf...</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>535fa30d7e25dd8a49f1536779734ec8286108d115da50...</td>\n",
       "      <td>7.871602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cfd77f44811ed62f25a220b53324cdbafc662a4c9e5f04...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015-06-11</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>5.344943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>937cff9e4dcfc2459620153dfc8b9962ac22bea67dfb29...</td>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>7.059346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      reservation_id                ...                 amount_spent_per_room_night_scaled\n",
       "0  07659f3758d8aee27f5a7e2887adeacb67021cb95ada1b...                ...                                           7.706428\n",
       "1  03930f033646d073462b35d411616323597715ac4fc398...                ...                                           6.662563\n",
       "2  d145a32920e6587ad95bfe299d80c0affa268220535aaf...                ...                                           7.871602\n",
       "3  cfd77f44811ed62f25a220b53324cdbafc662a4c9e5f04...                ...                                           5.344943\n",
       "4  937cff9e4dcfc2459620153dfc8b9962ac22bea67dfb29...                ...                                           7.059346\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a glimpse at first 5 rows of the dataframe\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (341424, 24) \n",
      "Test shape:(146765, 23)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train.shape} \\nTest shape:{test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#pandas_profiling.ProfileReport(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the value counts by dates, groupped to weeks for better visualization\n",
    "test.booking_date.value_counts().sort_values().asfreq(\"W\").plot.line(\n",
    "    color=\"red\", alpha=0.5\n",
    ")\n",
    "train.booking_date.value_counts().sort_values().asfreq(\"W\").plot.line(\n",
    "    color=\"blue\", alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_code_residence     0.013953\n",
       "season_holidayed_code    0.000334\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum().sort_values(ascending=False)[\n",
    "    train.isna().sum().sort_values(ascending=False) != 0\n",
    "] / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_code_residence     0.015399\n",
       "season_holidayed_code    0.000238\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum().sort_values(ascending=False)[\n",
    "    test.isna().sum().sort_values(ascending=False) != 0\n",
    "] / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(-999, inplace=True)\n",
    "test.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488189, 24)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the train and test to one dataframe for further processing\n",
    "df = pd.concat([train, test], sort=False)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the categorical features\n",
    "cat_cols = list(train.dtypes[train.dtypes == \"object\"].index)\n",
    "cat_cols += [\n",
    "    \"main_product_code\",\n",
    "    \"persontravellingid\",\n",
    "    \"resort_region_code\",\n",
    "    \"channel_code\",\n",
    "    \"resort_type_code\",\n",
    "    \"state_code_residence\",\n",
    "    \"booking_type_code\",\n",
    "    \"season_holidayed_code\",\n",
    "    \"state_code_resort\",\n",
    "    \"room_type_booked_code\",\n",
    "]\n",
    "\n",
    "# Convert selected columns to categories\n",
    "df.loc[:, cat_cols] = df.loc[:, cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features\n",
    "df[\"home_state\"] = df[\"state_code_residence\"].astype(int) == df[\n",
    "    \"state_code_resort\"\n",
    "].astype(int)\n",
    "df[\"family_number\"] = df[\"numberofadults\"] + df[\"numberofchildren\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_state                                      bool\n",
       "reservation_id                              category\n",
       "booking_type_code                           category\n",
       "member_age_buckets                          category\n",
       "reservationstatusid_code                    category\n",
       "state_code_resort                           category\n",
       "state_code_residence                        category\n",
       "season_holidayed_code                       category\n",
       "room_type_booked_code                       category\n",
       "memberid                                    category\n",
       "resort_type_code                            category\n",
       "persontravellingid                          category\n",
       "resort_id                                   category\n",
       "main_product_code                           category\n",
       "channel_code                                category\n",
       "resort_region_code                          category\n",
       "cluster_code                                category\n",
       "checkout_date                         datetime64[ns]\n",
       "checkin_date                          datetime64[ns]\n",
       "booking_date                          datetime64[ns]\n",
       "amount_spent_per_room_night_scaled           float64\n",
       "roomnights                                     int64\n",
       "numberofchildren                               int64\n",
       "numberofadults                                 int64\n",
       "total_pax                                      int64\n",
       "family_number                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of the featuers\n",
    "df.dtypes.astype(\"str\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in log1p\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "num_cols = [\n",
    "    \"roomnights\",\n",
    "    \"numberofchildren\",\n",
    "    \"numberofadults\",\n",
    "    \"total_pax\",\n",
    "    \"family_number\",\n",
    "]\n",
    "df[num_cols] = np.log1p(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The secret weapon from https://github.com/fastai/fastai/blob/master/old/fastai/structured.py\n",
    "def add_datepart(df, fldname, drop=True, time=False, errors=\"raise\"):\n",
    "    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n",
    "    the information from the date. This applies changes inplace.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame. df gain several new columns.\n",
    "    fldname: A string that is the name of the date column you wish to expand.\n",
    "        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n",
    "    drop: If true then the original date column will be removed.\n",
    "    time: If true time features: Hour, Minute, Second will be added.\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n",
    "    >>> df\n",
    "        A\n",
    "    0   2000-03-11\n",
    "    1   2000-03-12\n",
    "    2   2000-03-13\n",
    "    >>> add_datepart(df, 'A')\n",
    "    >>> df\n",
    "        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n",
    "    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n",
    "    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n",
    "    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n",
    "    \"\"\"\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(\n",
    "            fld, infer_datetime_format=True, errors=errors\n",
    "        )\n",
    "    targ_pre = re.sub(\"[Dd]ate$\", \"\", fldname)\n",
    "    attr = [\n",
    "        \"Year\",\n",
    "        \"Month\",\n",
    "        \"Week\",\n",
    "        \"Day\",\n",
    "        \"Dayofweek\",\n",
    "        \"Dayofyear\",\n",
    "        \"Is_month_end\",\n",
    "        \"Is_month_start\",\n",
    "        \"Is_quarter_end\",\n",
    "        \"Is_quarter_start\",\n",
    "        \"Is_year_end\",\n",
    "        \"Is_year_start\",\n",
    "    ]\n",
    "    if time:\n",
    "        attr = attr + [\"Hour\", \"Minute\", \"Second\"]\n",
    "    for n in attr:\n",
    "        df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    df[targ_pre + \"Elapsed\"] = fld.astype(np.int64) // 10 ** 9\n",
    "    if drop:\n",
    "        df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply add_datepart function to datetime features\n",
    "for col in [\"checkout_date\", \"checkin_date\", \"booking_date\"]:\n",
    "    add_datepart(df, col, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature days staying in the hotel\n",
    "df[\"days_stay\"] = df[\"checkout_date\"] - df[\"checkin_date\"]\n",
    "\n",
    "# New feature days from booking to checkin date\n",
    "df[\"days_wait\"] = df[\"checkin_date\"] - df[\"booking_date\"]\n",
    "\n",
    "# fix some inconsistencies in the data\n",
    "df.loc[df[\"days_wait\"].astype(int) < 0, \"checkout_date\"] = df[\"checkout_date\"][\n",
    "    df[\"days_wait\"].astype(int) < 0\n",
    "].apply(lambda x: x.replace(year=2018))\n",
    "df.loc[df[\"days_wait\"].astype(int) < 0, \"checkin_date\"] = df[\"checkin_date\"][\n",
    "    df[\"days_wait\"].astype(int) < 0\n",
    "].apply(lambda x: x.replace(year=2018))\n",
    "\n",
    "df[\"days_wait\"] = df[\"checkin_date\"] - df[\"booking_date\"]\n",
    "df.loc[df[\"days_wait\"].astype(int) < 0, \"days_wait\"] = datetime.timedelta(0)\n",
    "df[[\"days_stay\", \"days_wait\"]] = df[[\"days_stay\", \"days_wait\"]].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_pax_vs_family_number\"] = df.total_pax - df.family_number\n",
    "df[\"children_ratio\"] = df.family_number / df.numberofchildren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols += [\"days_stay\", \"days_wait\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pf = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "poly_df = pd.DataFrame(pf.fit_transform(df[num_cols].fillna(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df.reset_index(drop=True), poly_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we will not need for training\n",
    "drop_cols = [\n",
    "    \"reservation_id\",\n",
    "    \"amount_spent_per_room_night_scaled\",\n",
    "    \"checkout_date\",\n",
    "    \"checkin_date\",\n",
    "    \"booking_date\",\n",
    "    \"memberid\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = df2[~df2.amount_spent_per_room_night_scaled.isna()].drop(drop_cols, axis=1)\n",
    "y_total = df2[\n",
    "    ~df2.amount_spent_per_room_night_scaled.isna()\n",
    "].amount_spent_per_room_night_scaled.values\n",
    "\n",
    "X_test = df2[df2.amount_spent_per_room_night_scaled.isna()].drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in cat_cols if c in X_total.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = list(df.nunique().index[df.nunique() == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols += binary\n",
    "cat_cols = list(set(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Categorical Variables\n",
    "def column_index(df, query_cols):\n",
    "    cols = df.columns.values.astype(str)\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, query_cols, sorter=sidx)]\n",
    "\n",
    "\n",
    "cat_feats_pos = column_index(X_total, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_total, y_total, shuffle=True, random_state=42, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctb = CatBoostRegressor(iterations=5000, learning_rate=0.05)\n",
    "model_lgb = LGBMRegressor(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=5000,\n",
    "    random_state=42,\n",
    "    subsample=0.8,\n",
    "    reg_alpha=1,\n",
    "    reg_labmda=1,\n",
    "    colsample_bytree=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT withStratified KFold\n",
    "def kfold_gbm(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    y_total,\n",
    "    clf,\n",
    "    num_folds=5,\n",
    "    stratified=False,\n",
    "    debug=False,\n",
    "    random_state=42,\n",
    "    feature_importance=False,\n",
    "):\n",
    "    clf_name = type(clf).__name__\n",
    "    print(\n",
    "        f\"Starting {clf_name}. Train shape: {train_df.shape}, test shape: {test_df.shape}\"\n",
    "    )\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(\n",
    "            n_splits=num_folds, shuffle=True, random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, y_total)):\n",
    "        train_x, train_y = train_df.iloc[train_idx, :], y_total[train_idx]\n",
    "        valid_x, valid_y = train_df.iloc[valid_idx, :], y_total[valid_idx]\n",
    "\n",
    "        # GBM\n",
    "        if clf_name in [\"CatBoostRegressor\", \"XGBRegressor\"]:\n",
    "            clf.fit(\n",
    "                train_x,\n",
    "                train_y,\n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                verbose=100,\n",
    "                early_stopping_rounds=200,\n",
    "            )\n",
    "\n",
    "        elif clf_name in [\"LGBMRegressor\"]:\n",
    "            clf.fit(\n",
    "                train_x,\n",
    "                train_y,\n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                verbose=100,\n",
    "                early_stopping_rounds=200,\n",
    "                eval_metric=\"rmse\",\n",
    "            )\n",
    "        # sklearn\n",
    "        else:\n",
    "            clf.fit(train_x, train_y)\n",
    "\n",
    "        if clf_name == \"LGBMRegressor\":\n",
    "            oof_preds[valid_idx] = clf.predict(\n",
    "                valid_x, num_iteration=clf.best_iteration_\n",
    "            )\n",
    "            sub_preds += (\n",
    "                clf.predict(test_df, num_iteration=clf.best_iteration_) / folds.n_splits\n",
    "            )\n",
    "        elif clf_name == \"CatBoostRegressor\":\n",
    "            oof_preds[valid_idx] = clf.predict(valid_x)\n",
    "            sub_preds += clf.predict(test_df) / folds.n_splits\n",
    "        elif clf_name == \"XGBRegressor\":\n",
    "            oof_preds[valid_idx] = clf.predict(\n",
    "                valid_x, ntree_limit=clf.best_ntree_limit\n",
    "            )\n",
    "            sub_preds += (\n",
    "                clf.predict(test_df, ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "            )\n",
    "        else:\n",
    "            oof_preds[valid_idx] = clf.predict(valid_x)\n",
    "            sub_preds += clf.predict(test_df) / folds.n_splits\n",
    "\n",
    "        if feature_importance:\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat(\n",
    "                [feature_importance_df, fold_importance_df], axis=0\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"Fold %2d Score : %.6f\"\n",
    "            % (n_fold + 1, np.sqrt(mean_squared_error(valid_y, oof_preds[valid_idx])))\n",
    "        )\n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    full_score = np.sqrt(mean_squared_error(y_total, oof_preds))\n",
    "    print(\"Full Score %.6f \\n\\n\" % full_score)\n",
    "\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        sample_submission[\"amount_spent_per_room_night_scaled\"] = sub_preds\n",
    "        sample_submission.to_csv(\n",
    "            f\"submission_kernel_{clf_name}_{full_score:.4f}.csv\", index=False\n",
    "        )\n",
    "\n",
    "    if feature_importance:\n",
    "        display_importances(feature_importance_df)\n",
    "        return oof_preds, sub_preds, feature_importance_df\n",
    "    else:\n",
    "        return oof_preds, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_ctb, model_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacker_n_blender(\n",
    "    X_train=X_total, X_test=X_test, y=y_total, models=models, seed=42, debug=False\n",
    "):\n",
    "    np.random.seed(42)\n",
    "    X_train_meta = 0.03 * np.random.randn(X_train.shape[0], len(models))\n",
    "    X_test_meta = np.zeros((X_test.shape[0], len(models)))\n",
    "\n",
    "    for t, model in enumerate(models):\n",
    "        oof_preds, sub_preds = kfold_gbm(\n",
    "            X_train, X_test, y_total, clf=model, random_state=42, debug=debug\n",
    "        )\n",
    "        if debug:\n",
    "            print(\n",
    "                f\"{type(model).__name__} Score: {roc_auc_score(y_valid, sub_preds):.4f}\\n\"\n",
    "            )\n",
    "        X_train_meta[:, t] += oof_preds\n",
    "        X_test_meta[:, t] = sub_preds\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    ens_model = Ridge(0.001).fit(X_train_meta, y.reshape(-1, 1))\n",
    "    stack = ens_model.predict(X_test_meta)\n",
    "    blend = X_test_meta.mean(axis=1)\n",
    "\n",
    "    return stack, blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoostRegressor. Train shape: (341424, 98), test shape: (146765, 98)\n",
      "0:\tlearn: 7.4143422\ttest: 7.4143422\ttest1: 7.4196166\tbest: 7.4196166 (0)\ttotal: 141ms\tremaining: 11m 47s\n",
      "100:\tlearn: 0.9963294\ttest: 0.9963294\ttest1: 0.9976218\tbest: 0.9976218 (100)\ttotal: 13.5s\tremaining: 10m 57s\n",
      "200:\tlearn: 0.9841233\ttest: 0.9841233\ttest1: 0.9865393\tbest: 0.9865393 (200)\ttotal: 26.1s\tremaining: 10m 23s\n",
      "300:\tlearn: 0.9798819\ttest: 0.9798819\ttest1: 0.9836310\tbest: 0.9836310 (300)\ttotal: 38.6s\tremaining: 10m 1s\n",
      "400:\tlearn: 0.9770036\ttest: 0.9770036\ttest1: 0.9821343\tbest: 0.9821343 (400)\ttotal: 50.3s\tremaining: 9m 36s\n",
      "500:\tlearn: 0.9747318\ttest: 0.9747318\ttest1: 0.9813700\tbest: 0.9813700 (500)\ttotal: 1m 1s\tremaining: 9m 15s\n",
      "600:\tlearn: 0.9728697\ttest: 0.9728697\ttest1: 0.9808102\tbest: 0.9808102 (600)\ttotal: 1m 13s\tremaining: 8m 57s\n",
      "700:\tlearn: 0.9712329\ttest: 0.9712329\ttest1: 0.9803825\tbest: 0.9803825 (700)\ttotal: 1m 24s\tremaining: 8m 41s\n",
      "800:\tlearn: 0.9696362\ttest: 0.9696362\ttest1: 0.9801142\tbest: 0.9801028 (797)\ttotal: 1m 36s\tremaining: 8m 27s\n",
      "900:\tlearn: 0.9681473\ttest: 0.9681473\ttest1: 0.9798296\tbest: 0.9798296 (900)\ttotal: 1m 48s\tremaining: 8m 14s\n",
      "1000:\tlearn: 0.9666983\ttest: 0.9666983\ttest1: 0.9795472\tbest: 0.9795472 (1000)\ttotal: 2m\tremaining: 8m 1s\n",
      "1100:\tlearn: 0.9654050\ttest: 0.9654050\ttest1: 0.9794376\tbest: 0.9794374 (1092)\ttotal: 2m 12s\tremaining: 7m 48s\n",
      "1200:\tlearn: 0.9641053\ttest: 0.9641053\ttest1: 0.9792974\tbest: 0.9792918 (1198)\ttotal: 2m 24s\tremaining: 7m 35s\n",
      "1300:\tlearn: 0.9628781\ttest: 0.9628781\ttest1: 0.9791802\tbest: 0.9791794 (1299)\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1400:\tlearn: 0.9617477\ttest: 0.9617477\ttest1: 0.9791516\tbest: 0.9791310 (1372)\ttotal: 2m 47s\tremaining: 7m 9s\n",
      "1500:\tlearn: 0.9605178\ttest: 0.9605178\ttest1: 0.9791083\tbest: 0.9790791 (1478)\ttotal: 2m 59s\tremaining: 6m 57s\n",
      "1600:\tlearn: 0.9593491\ttest: 0.9593491\ttest1: 0.9790547\tbest: 0.9790547 (1600)\ttotal: 3m 11s\tremaining: 6m 45s\n",
      "1700:\tlearn: 0.9581596\ttest: 0.9581596\ttest1: 0.9790072\tbest: 0.9790005 (1698)\ttotal: 3m 23s\tremaining: 6m 33s\n",
      "1800:\tlearn: 0.9569520\ttest: 0.9569520\ttest1: 0.9790243\tbest: 0.9789948 (1745)\ttotal: 3m 35s\tremaining: 6m 22s\n",
      "1900:\tlearn: 0.9558869\ttest: 0.9558869\ttest1: 0.9790409\tbest: 0.9789948 (1745)\ttotal: 3m 47s\tremaining: 6m 10s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9789947844\n",
      "bestIteration = 1745\n",
      "\n",
      "Shrink model to first 1746 iterations.\n",
      "Fold  1 Score : 0.978995\n",
      "0:\tlearn: 7.4155496\ttest: 7.4155496\ttest1: 7.4144514\tbest: 7.4144514 (0)\ttotal: 104ms\tremaining: 8m 39s\n",
      "100:\tlearn: 0.9965702\ttest: 0.9965702\ttest1: 0.9970433\tbest: 0.9970433 (100)\ttotal: 13.9s\tremaining: 11m 14s\n",
      "200:\tlearn: 0.9841773\ttest: 0.9841773\ttest1: 0.9855274\tbest: 0.9855274 (200)\ttotal: 26.6s\tremaining: 10m 34s\n",
      "300:\tlearn: 0.9799511\ttest: 0.9799511\ttest1: 0.9825701\tbest: 0.9825701 (300)\ttotal: 38.6s\tremaining: 10m 3s\n",
      "400:\tlearn: 0.9771479\ttest: 0.9771479\ttest1: 0.9812627\tbest: 0.9812610 (399)\ttotal: 50.3s\tremaining: 9m 37s\n",
      "500:\tlearn: 0.9748569\ttest: 0.9748569\ttest1: 0.9803546\tbest: 0.9803515 (499)\ttotal: 1m 2s\tremaining: 9m 18s\n",
      "600:\tlearn: 0.9729632\ttest: 0.9729632\ttest1: 0.9798489\tbest: 0.9798489 (600)\ttotal: 1m 13s\tremaining: 9m\n",
      "700:\tlearn: 0.9712627\ttest: 0.9712627\ttest1: 0.9794735\tbest: 0.9794635 (696)\ttotal: 1m 25s\tremaining: 8m 45s\n",
      "800:\tlearn: 0.9696653\ttest: 0.9696653\ttest1: 0.9791417\tbest: 0.9791417 (800)\ttotal: 1m 38s\tremaining: 8m 34s\n",
      "900:\tlearn: 0.9681019\ttest: 0.9681019\ttest1: 0.9788750\tbest: 0.9788750 (900)\ttotal: 1m 50s\tremaining: 8m 20s\n",
      "1000:\tlearn: 0.9667530\ttest: 0.9667530\ttest1: 0.9786899\tbest: 0.9786899 (1000)\ttotal: 2m 1s\tremaining: 8m 7s\n",
      "1100:\tlearn: 0.9653895\ttest: 0.9653895\ttest1: 0.9785417\tbest: 0.9785316 (1096)\ttotal: 2m 14s\tremaining: 7m 54s\n",
      "1200:\tlearn: 0.9641194\ttest: 0.9641194\ttest1: 0.9784570\tbest: 0.9784570 (1200)\ttotal: 2m 25s\tremaining: 7m 41s\n",
      "1300:\tlearn: 0.9628813\ttest: 0.9628813\ttest1: 0.9784243\tbest: 0.9783967 (1282)\ttotal: 2m 37s\tremaining: 7m 27s\n",
      "1400:\tlearn: 0.9616603\ttest: 0.9616603\ttest1: 0.9783426\tbest: 0.9783269 (1394)\ttotal: 2m 49s\tremaining: 7m 15s\n",
      "1500:\tlearn: 0.9605156\ttest: 0.9605156\ttest1: 0.9783048\tbest: 0.9783048 (1500)\ttotal: 3m 1s\tremaining: 7m 2s\n",
      "1600:\tlearn: 0.9593708\ttest: 0.9593708\ttest1: 0.9782554\tbest: 0.9782554 (1600)\ttotal: 3m 13s\tremaining: 6m 49s\n",
      "1700:\tlearn: 0.9582668\ttest: 0.9582668\ttest1: 0.9782883\tbest: 0.9782405 (1634)\ttotal: 3m 24s\tremaining: 6m 37s\n",
      "1800:\tlearn: 0.9571289\ttest: 0.9571289\ttest1: 0.9782300\tbest: 0.9782300 (1800)\ttotal: 3m 36s\tremaining: 6m 24s\n",
      "1900:\tlearn: 0.9560889\ttest: 0.9560889\ttest1: 0.9781996\tbest: 0.9781899 (1827)\ttotal: 3m 48s\tremaining: 6m 12s\n",
      "2000:\tlearn: 0.9550570\ttest: 0.9550570\ttest1: 0.9782242\tbest: 0.9781859 (1969)\ttotal: 4m\tremaining: 5m 59s\n",
      "2100:\tlearn: 0.9539960\ttest: 0.9539960\ttest1: 0.9782517\tbest: 0.9781859 (1969)\ttotal: 4m 12s\tremaining: 5m 48s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9781859381\n",
      "bestIteration = 1969\n",
      "\n",
      "Shrink model to first 1970 iterations.\n",
      "Fold  2 Score : 0.978186\n",
      "0:\tlearn: 7.4148120\ttest: 7.4148120\ttest1: 7.4176265\tbest: 7.4176265 (0)\ttotal: 94.3ms\tremaining: 7m 51s\n",
      "100:\tlearn: 0.9967937\ttest: 0.9967937\ttest1: 0.9956978\tbest: 0.9956978 (100)\ttotal: 13.4s\tremaining: 10m 51s\n",
      "200:\tlearn: 0.9841228\ttest: 0.9841228\ttest1: 0.9843795\tbest: 0.9843795 (200)\ttotal: 26.2s\tremaining: 10m 25s\n",
      "300:\tlearn: 0.9801265\ttest: 0.9801265\ttest1: 0.9818857\tbest: 0.9818857 (300)\ttotal: 39s\tremaining: 10m 9s\n",
      "400:\tlearn: 0.9772175\ttest: 0.9772175\ttest1: 0.9805210\tbest: 0.9805210 (400)\ttotal: 51s\tremaining: 9m 45s\n",
      "500:\tlearn: 0.9752120\ttest: 0.9752120\ttest1: 0.9798670\tbest: 0.9798670 (500)\ttotal: 1m 2s\tremaining: 9m 21s\n",
      "600:\tlearn: 0.9732373\ttest: 0.9732373\ttest1: 0.9791548\tbest: 0.9791548 (600)\ttotal: 1m 14s\tremaining: 9m 4s\n",
      "700:\tlearn: 0.9716448\ttest: 0.9716448\ttest1: 0.9787287\tbest: 0.9787287 (700)\ttotal: 1m 26s\tremaining: 8m 47s\n",
      "800:\tlearn: 0.9700788\ttest: 0.9700788\ttest1: 0.9782727\tbest: 0.9782704 (799)\ttotal: 1m 37s\tremaining: 8m 32s\n",
      "900:\tlearn: 0.9685902\ttest: 0.9685902\ttest1: 0.9780354\tbest: 0.9780335 (899)\ttotal: 1m 49s\tremaining: 8m 18s\n",
      "1000:\tlearn: 0.9672998\ttest: 0.9672998\ttest1: 0.9780152\tbest: 0.9779972 (943)\ttotal: 2m 1s\tremaining: 8m 4s\n",
      "1100:\tlearn: 0.9660018\ttest: 0.9660018\ttest1: 0.9777819\tbest: 0.9777819 (1100)\ttotal: 2m 13s\tremaining: 7m 52s\n",
      "1200:\tlearn: 0.9646826\ttest: 0.9646826\ttest1: 0.9775895\tbest: 0.9775895 (1200)\ttotal: 2m 25s\tremaining: 7m 39s\n",
      "1300:\tlearn: 0.9634355\ttest: 0.9634355\ttest1: 0.9774403\tbest: 0.9774403 (1300)\ttotal: 2m 37s\tremaining: 7m 26s\n",
      "1400:\tlearn: 0.9622319\ttest: 0.9622319\ttest1: 0.9773253\tbest: 0.9773253 (1400)\ttotal: 2m 48s\tremaining: 7m 13s\n",
      "1500:\tlearn: 0.9610969\ttest: 0.9610969\ttest1: 0.9773154\tbest: 0.9773013 (1409)\ttotal: 3m\tremaining: 7m 1s\n",
      "1600:\tlearn: 0.9598854\ttest: 0.9598854\ttest1: 0.9772301\tbest: 0.9772283 (1590)\ttotal: 3m 12s\tremaining: 6m 49s\n",
      "1700:\tlearn: 0.9587745\ttest: 0.9587745\ttest1: 0.9771780\tbest: 0.9771776 (1699)\ttotal: 3m 24s\tremaining: 6m 37s\n",
      "1800:\tlearn: 0.9577051\ttest: 0.9577051\ttest1: 0.9771580\tbest: 0.9771502 (1795)\ttotal: 3m 36s\tremaining: 6m 24s\n",
      "1900:\tlearn: 0.9567239\ttest: 0.9567239\ttest1: 0.9772097\tbest: 0.9771484 (1806)\ttotal: 3m 48s\tremaining: 6m 12s\n",
      "2000:\tlearn: 0.9556735\ttest: 0.9556735\ttest1: 0.9771996\tbest: 0.9771484 (1806)\ttotal: 4m\tremaining: 5m 59s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9771484275\n",
      "bestIteration = 1806\n",
      "\n",
      "Shrink model to first 1807 iterations.\n",
      "Fold  3 Score : 0.977148\n",
      "0:\tlearn: 7.4153135\ttest: 7.4153135\ttest1: 7.4154869\tbest: 7.4154869 (0)\ttotal: 97.3ms\tremaining: 8m 6s\n",
      "100:\tlearn: 0.9969950\ttest: 0.9969950\ttest1: 0.9962012\tbest: 0.9962012 (100)\ttotal: 13.6s\tremaining: 10m 58s\n",
      "200:\tlearn: 0.9843277\ttest: 0.9843277\ttest1: 0.9847478\tbest: 0.9847478 (200)\ttotal: 26.3s\tremaining: 10m 27s\n",
      "300:\tlearn: 0.9801566\ttest: 0.9801566\ttest1: 0.9818231\tbest: 0.9818231 (300)\ttotal: 38.1s\tremaining: 9m 55s\n",
      "400:\tlearn: 0.9772498\ttest: 0.9772498\ttest1: 0.9803969\tbest: 0.9803969 (400)\ttotal: 50s\tremaining: 9m 33s\n",
      "500:\tlearn: 0.9751202\ttest: 0.9751202\ttest1: 0.9796133\tbest: 0.9796115 (496)\ttotal: 1m 1s\tremaining: 9m 13s\n",
      "600:\tlearn: 0.9731576\ttest: 0.9731576\ttest1: 0.9789911\tbest: 0.9789879 (599)\ttotal: 1m 13s\tremaining: 8m 56s\n",
      "700:\tlearn: 0.9714292\ttest: 0.9714292\ttest1: 0.9785764\tbest: 0.9785764 (700)\ttotal: 1m 25s\tremaining: 8m 41s\n",
      "800:\tlearn: 0.9698610\ttest: 0.9698610\ttest1: 0.9783248\tbest: 0.9783248 (800)\ttotal: 1m 37s\tremaining: 8m 30s\n",
      "900:\tlearn: 0.9683739\ttest: 0.9683739\ttest1: 0.9781623\tbest: 0.9781623 (900)\ttotal: 1m 48s\tremaining: 8m 15s\n",
      "1000:\tlearn: 0.9670511\ttest: 0.9670511\ttest1: 0.9780216\tbest: 0.9780216 (1000)\ttotal: 2m\tremaining: 8m 1s\n",
      "1100:\tlearn: 0.9657166\ttest: 0.9657166\ttest1: 0.9778437\tbest: 0.9778407 (1099)\ttotal: 2m 12s\tremaining: 7m 48s\n",
      "1200:\tlearn: 0.9643916\ttest: 0.9643916\ttest1: 0.9777160\tbest: 0.9777071 (1186)\ttotal: 2m 23s\tremaining: 7m 34s\n",
      "1300:\tlearn: 0.9631319\ttest: 0.9631319\ttest1: 0.9776136\tbest: 0.9776136 (1300)\ttotal: 2m 35s\tremaining: 7m 21s\n",
      "1400:\tlearn: 0.9618751\ttest: 0.9618751\ttest1: 0.9775258\tbest: 0.9775248 (1394)\ttotal: 2m 47s\tremaining: 7m 9s\n",
      "1500:\tlearn: 0.9607143\ttest: 0.9607143\ttest1: 0.9774716\tbest: 0.9774691 (1497)\ttotal: 2m 59s\tremaining: 6m 58s\n",
      "1600:\tlearn: 0.9594990\ttest: 0.9594990\ttest1: 0.9774019\tbest: 0.9773919 (1578)\ttotal: 3m 11s\tremaining: 6m 45s\n",
      "1700:\tlearn: 0.9583978\ttest: 0.9583978\ttest1: 0.9773810\tbest: 0.9773702 (1672)\ttotal: 3m 22s\tremaining: 6m 33s\n",
      "1800:\tlearn: 0.9573135\ttest: 0.9573135\ttest1: 0.9773774\tbest: 0.9773675 (1761)\ttotal: 3m 34s\tremaining: 6m 21s\n",
      "1900:\tlearn: 0.9561876\ttest: 0.9561876\ttest1: 0.9773164\tbest: 0.9773096 (1878)\ttotal: 3m 46s\tremaining: 6m 9s\n",
      "2000:\tlearn: 0.9551321\ttest: 0.9551321\ttest1: 0.9773369\tbest: 0.9772942 (1928)\ttotal: 3m 58s\tremaining: 5m 57s\n",
      "2100:\tlearn: 0.9540843\ttest: 0.9540843\ttest1: 0.9773278\tbest: 0.9772942 (1928)\ttotal: 4m 10s\tremaining: 5m 45s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.977294206\n",
      "bestIteration = 1928\n",
      "\n",
      "Shrink model to first 1929 iterations.\n",
      "Fold  4 Score : 0.977294\n",
      "0:\tlearn: 7.4168274\ttest: 7.4168274\ttest1: 7.4096908\tbest: 7.4096908 (0)\ttotal: 129ms\tremaining: 10m 44s\n",
      "100:\tlearn: 0.9958781\ttest: 0.9958781\ttest1: 1.0012463\tbest: 1.0012463 (100)\ttotal: 13.5s\tremaining: 10m 53s\n",
      "200:\tlearn: 0.9829526\ttest: 0.9829526\ttest1: 0.9899999\tbest: 0.9899999 (200)\ttotal: 26.2s\tremaining: 10m 25s\n",
      "300:\tlearn: 0.9787630\ttest: 0.9787630\ttest1: 0.9870408\tbest: 0.9870408 (300)\ttotal: 38.1s\tremaining: 9m 54s\n",
      "400:\tlearn: 0.9759439\ttest: 0.9759439\ttest1: 0.9856780\tbest: 0.9856780 (400)\ttotal: 49.8s\tremaining: 9m 31s\n",
      "500:\tlearn: 0.9737815\ttest: 0.9737815\ttest1: 0.9847947\tbest: 0.9847947 (500)\ttotal: 1m 1s\tremaining: 9m 12s\n",
      "600:\tlearn: 0.9719220\ttest: 0.9719220\ttest1: 0.9842954\tbest: 0.9842954 (600)\ttotal: 1m 13s\tremaining: 8m 55s\n",
      "700:\tlearn: 0.9702578\ttest: 0.9702578\ttest1: 0.9838834\tbest: 0.9838834 (700)\ttotal: 1m 24s\tremaining: 8m 40s\n",
      "800:\tlearn: 0.9686859\ttest: 0.9686859\ttest1: 0.9834736\tbest: 0.9834736 (800)\ttotal: 1m 36s\tremaining: 8m 25s\n",
      "900:\tlearn: 0.9672598\ttest: 0.9672598\ttest1: 0.9831681\tbest: 0.9831681 (900)\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "1000:\tlearn: 0.9657913\ttest: 0.9657913\ttest1: 0.9830165\tbest: 0.9830117 (999)\ttotal: 1m 59s\tremaining: 7m 58s\n",
      "1100:\tlearn: 0.9643994\ttest: 0.9643994\ttest1: 0.9828232\tbest: 0.9828232 (1100)\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1200:\tlearn: 0.9631232\ttest: 0.9631232\ttest1: 0.9827152\tbest: 0.9827152 (1200)\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1300:\tlearn: 0.9619128\ttest: 0.9619128\ttest1: 0.9825714\tbest: 0.9825700 (1298)\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1400:\tlearn: 0.9606209\ttest: 0.9606209\ttest1: 0.9824462\tbest: 0.9824338 (1394)\ttotal: 2m 47s\tremaining: 7m 10s\n",
      "1500:\tlearn: 0.9593840\ttest: 0.9593840\ttest1: 0.9824074\tbest: 0.9824012 (1473)\ttotal: 2m 59s\tremaining: 6m 57s\n",
      "1600:\tlearn: 0.9581772\ttest: 0.9581772\ttest1: 0.9823563\tbest: 0.9823331 (1577)\ttotal: 3m 11s\tremaining: 6m 45s\n",
      "1700:\tlearn: 0.9571038\ttest: 0.9571038\ttest1: 0.9823099\tbest: 0.9822998 (1684)\ttotal: 3m 22s\tremaining: 6m 33s\n",
      "1800:\tlearn: 0.9560311\ttest: 0.9560311\ttest1: 0.9822639\tbest: 0.9822595 (1798)\ttotal: 3m 35s\tremaining: 6m 22s\n",
      "1900:\tlearn: 0.9549469\ttest: 0.9549469\ttest1: 0.9821781\tbest: 0.9821765 (1893)\ttotal: 3m 47s\tremaining: 6m 10s\n",
      "2000:\tlearn: 0.9539209\ttest: 0.9539209\ttest1: 0.9821406\tbest: 0.9821406 (2000)\ttotal: 3m 58s\tremaining: 5m 58s\n",
      "2100:\tlearn: 0.9529100\ttest: 0.9529100\ttest1: 0.9822127\tbest: 0.9821323 (2016)\ttotal: 4m 10s\tremaining: 5m 46s\n",
      "2200:\tlearn: 0.9518972\ttest: 0.9518972\ttest1: 0.9821721\tbest: 0.9821323 (2016)\ttotal: 4m 22s\tremaining: 5m 34s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9821322854\n",
      "bestIteration = 2016\n",
      "\n",
      "Shrink model to first 2017 iterations.\n",
      "Fold  5 Score : 0.982132\n",
      "Full Score 0.978753 \n",
      "\n",
      "\n",
      "Starting LGBMRegressor. Train shape: (341424, 98), test shape: (146765, 98)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 0.980752\ttraining's l2: 0.961875\tvalid_1's rmse: 0.984942\tvalid_1's l2: 0.970112\n",
      "[200]\ttraining's rmse: 0.97043\ttraining's l2: 0.941735\tvalid_1's rmse: 0.98035\tvalid_1's l2: 0.961085\n",
      "[300]\ttraining's rmse: 0.964346\ttraining's l2: 0.929963\tvalid_1's rmse: 0.979536\tvalid_1's l2: 0.95949\n",
      "[400]\ttraining's rmse: 0.959321\ttraining's l2: 0.920297\tvalid_1's rmse: 0.979216\tvalid_1's l2: 0.958865\n",
      "[500]\ttraining's rmse: 0.954633\ttraining's l2: 0.911325\tvalid_1's rmse: 0.979149\tvalid_1's l2: 0.958734\n",
      "[600]\ttraining's rmse: 0.950303\ttraining's l2: 0.903076\tvalid_1's rmse: 0.97907\tvalid_1's l2: 0.958579\n",
      "[700]\ttraining's rmse: 0.946166\ttraining's l2: 0.89523\tvalid_1's rmse: 0.97904\tvalid_1's l2: 0.95852\n",
      "[800]\ttraining's rmse: 0.942087\ttraining's l2: 0.887527\tvalid_1's rmse: 0.979047\tvalid_1's l2: 0.958532\n",
      "[900]\ttraining's rmse: 0.938322\ttraining's l2: 0.880448\tvalid_1's rmse: 0.979296\tvalid_1's l2: 0.959021\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's rmse: 0.945322\ttraining's l2: 0.893634\tvalid_1's rmse: 0.978993\tvalid_1's l2: 0.958428\n",
      "Fold  1 Score : 0.978993\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 0.981201\ttraining's l2: 0.962755\tvalid_1's rmse: 0.984078\tvalid_1's l2: 0.968409\n",
      "[200]\ttraining's rmse: 0.97098\ttraining's l2: 0.942801\tvalid_1's rmse: 0.979201\tvalid_1's l2: 0.958835\n",
      "[300]\ttraining's rmse: 0.964649\ttraining's l2: 0.930548\tvalid_1's rmse: 0.978391\tvalid_1's l2: 0.95725\n",
      "[400]\ttraining's rmse: 0.959508\ttraining's l2: 0.920656\tvalid_1's rmse: 0.978228\tvalid_1's l2: 0.956929\n",
      "[500]\ttraining's rmse: 0.9548\ttraining's l2: 0.911643\tvalid_1's rmse: 0.978184\tvalid_1's l2: 0.956844\n",
      "[600]\ttraining's rmse: 0.950412\ttraining's l2: 0.903284\tvalid_1's rmse: 0.978137\tvalid_1's l2: 0.956752\n",
      "[700]\ttraining's rmse: 0.946214\ttraining's l2: 0.895322\tvalid_1's rmse: 0.978213\tvalid_1's l2: 0.956901\n",
      "Early stopping, best iteration is:\n",
      "[587]\ttraining's rmse: 0.950961\ttraining's l2: 0.904326\tvalid_1's rmse: 0.978101\tvalid_1's l2: 0.956683\n",
      "Fold  2 Score : 0.978101\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 0.981094\ttraining's l2: 0.962546\tvalid_1's rmse: 0.983395\tvalid_1's l2: 0.967066\n",
      "[200]\ttraining's rmse: 0.970934\ttraining's l2: 0.942714\tvalid_1's rmse: 0.978854\tvalid_1's l2: 0.958154\n",
      "[300]\ttraining's rmse: 0.964762\ttraining's l2: 0.930766\tvalid_1's rmse: 0.977947\tvalid_1's l2: 0.95638\n",
      "[400]\ttraining's rmse: 0.959647\ttraining's l2: 0.920922\tvalid_1's rmse: 0.977658\tvalid_1's l2: 0.955816\n",
      "[500]\ttraining's rmse: 0.954836\ttraining's l2: 0.911712\tvalid_1's rmse: 0.977551\tvalid_1's l2: 0.955605\n",
      "[600]\ttraining's rmse: 0.950438\ttraining's l2: 0.903333\tvalid_1's rmse: 0.977403\tvalid_1's l2: 0.955316\n",
      "[700]\ttraining's rmse: 0.946184\ttraining's l2: 0.895264\tvalid_1's rmse: 0.977386\tvalid_1's l2: 0.955284\n",
      "[800]\ttraining's rmse: 0.942267\ttraining's l2: 0.887867\tvalid_1's rmse: 0.977531\tvalid_1's l2: 0.955568\n",
      "Early stopping, best iteration is:\n",
      "[645]\ttraining's rmse: 0.948471\ttraining's l2: 0.899597\tvalid_1's rmse: 0.977342\tvalid_1's l2: 0.955198\n",
      "Fold  3 Score : 0.977342\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 0.98151\ttraining's l2: 0.963362\tvalid_1's rmse: 0.982953\tvalid_1's l2: 0.966196\n",
      "[200]\ttraining's rmse: 0.971254\ttraining's l2: 0.943334\tvalid_1's rmse: 0.978369\tvalid_1's l2: 0.957206\n",
      "[300]\ttraining's rmse: 0.965048\ttraining's l2: 0.931318\tvalid_1's rmse: 0.97746\tvalid_1's l2: 0.955428\n",
      "[400]\ttraining's rmse: 0.959906\ttraining's l2: 0.92142\tvalid_1's rmse: 0.977222\tvalid_1's l2: 0.954962\n",
      "[500]\ttraining's rmse: 0.955219\ttraining's l2: 0.912443\tvalid_1's rmse: 0.977138\tvalid_1's l2: 0.954799\n",
      "[600]\ttraining's rmse: 0.950825\ttraining's l2: 0.904068\tvalid_1's rmse: 0.977033\tvalid_1's l2: 0.954593\n",
      "[700]\ttraining's rmse: 0.94656\ttraining's l2: 0.895976\tvalid_1's rmse: 0.976915\tvalid_1's l2: 0.954363\n",
      "[800]\ttraining's rmse: 0.942624\ttraining's l2: 0.888539\tvalid_1's rmse: 0.976972\tvalid_1's l2: 0.954474\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's rmse: 0.946906\ttraining's l2: 0.89663\tvalid_1's rmse: 0.976886\tvalid_1's l2: 0.954306\n",
      "Fold  4 Score : 0.976886\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 0.979883\ttraining's l2: 0.96017\tvalid_1's rmse: 0.989472\tvalid_1's l2: 0.979055\n",
      "[200]\ttraining's rmse: 0.969713\ttraining's l2: 0.940343\tvalid_1's rmse: 0.984603\tvalid_1's l2: 0.969443\n",
      "[300]\ttraining's rmse: 0.963479\ttraining's l2: 0.928292\tvalid_1's rmse: 0.983534\tvalid_1's l2: 0.967339\n",
      "[400]\ttraining's rmse: 0.958378\ttraining's l2: 0.918488\tvalid_1's rmse: 0.983212\tvalid_1's l2: 0.966706\n",
      "[500]\ttraining's rmse: 0.953755\ttraining's l2: 0.909649\tvalid_1's rmse: 0.983142\tvalid_1's l2: 0.966568\n",
      "[600]\ttraining's rmse: 0.949332\ttraining's l2: 0.901232\tvalid_1's rmse: 0.983183\tvalid_1's l2: 0.966649\n",
      "[700]\ttraining's rmse: 0.945176\ttraining's l2: 0.893357\tvalid_1's rmse: 0.983158\tvalid_1's l2: 0.9666\n",
      "Early stopping, best iteration is:\n",
      "[546]\ttraining's rmse: 0.951698\ttraining's l2: 0.90573\tvalid_1's rmse: 0.98306\tvalid_1's l2: 0.966407\n",
      "Fold  5 Score : 0.983060\n",
      "Full Score 0.978879 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stack, blend = stacker_n_blender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"amount_spent_per_room_night_scaled\"] = stack\n",
    "sample_submission.to_csv(\"submission_kernel_stack.csv\", index=False)\n",
    "\n",
    "sample_submission[\"amount_spent_per_room_night_scaled\"] = blend\n",
    "sample_submission.to_csv(\"submission_kernel_blend.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
